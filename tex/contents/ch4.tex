\chapter{Methods and Experiments}\label{ch:ch4}
Given the relevant background research and knowledge base, we will now describe the experiments we ran and the reason behind our experimental methods. Given the powerful advances in NLP due to the Transformer discussed in \ref{sec:transformers}, our general goal was to to investigate the results of the Transformer in application to EMP generation, which to our knowledge has never been done. Because both language and music are highly sequential and hierarchical in nature, our intuition was that because the Transformer does a good job of learning the general structure of language, that it can do the same of for music. We use the general framework for a complete end to end performance generation system which is proposed by virtuosoNet. In its simplicity, this purpose of this project is to determine if a Transformer based model can improve upon virtuosoNet, given the same data, features, and evaluation metrics\rtodo[,inline]{Make sure to add section about feature engineering with virtuosoNet}.

\section{Data and Features}
The reasons for the adoption of the virtuosoNet system are twofold: the first being that the dataset used to develop virtuosoNet was the largest publicly available dataset used in EMP generation, and the second being that the code and models of virtuosoNet are open sourced \footnote{https://github.com/jdasam/virtuosoNet} and contain all of the necessary data processing. This system also somewhat represents the "state of the art" in EMP generation, so it provides a natural starting place to use for comparison against any further model development. The virtusoNet system uses handcrafted features for both scores and performances. Score features contain low-level information (pitch and timing), high level information such as the key and metric information, as well as more detailed information such as the duration of rests, articulation markings (legato and staccato), and the distance from the closest preceeding tempo and dynamics directions, slur, and beam status. The performance features include all of the standard performance features: tempo expressed as BPM, note onset deviation, MIDI velocity, articulation, and different features related to the onset and offset times of the pedal. 

\section{Model}
In the virtuosoNet system, there is a 1:1 mapping between notes in scores and performances. The original Transformer as an encoder-decoder model was designed as a seq-2-seq model where the sequences have different lengths, which adds additional complexities into the model to account for this difference. To keep our system simple, our model is conceptually similar to BERT, and acts as an encoder-only Transformer model.  It contains a simple fully connected linear layer on top which will learn the final mapping between the Transformer encoding and the actual score features. We use the standard absolute positional embedding which is concatenated with the score features as input to the model. The performance output features of the model can be used to construct a MIDI file, allowing for the system to performance full performance generation given a score in MusicXML form. 

\section{Experiments and Evaluation}
virtuosoNet is built as a regression model and uses MSE as both its loss function and evaluation metric. It uses a 8-1-1 train/valid/test data split, and \citet{jeong2019virtuosonet} present MSE results for each different parameter of the performance features on the test set. We follow the same method for our quantitative evaluation. 



%     \item We will experiment with a transformer encoder only architecture similar to BERT. The problem includes a 1-1 to mapping between every note in the score and a related note in a performance. This is different than seq-2-seq modeling problem such as neural machine translation which maps a sequence of one length to another sequence of a different length, which is what the full Transformer architecture was intended for. The Transformer Encoder can be seen as as a large encoder that learns the best representation for a given feature set. The model we'll build will use a simple FFNN that accepts the output of the transformer encoder to decode this representation and give the final feature set which is then used to create a performance. This is similar to the BERT architecture and it's intended application. \rtodo[,inline]{Come up with a more detailed explanation of this modeling choice. Also create a visual diagram that explains the transformer encoder with the simple regression model sitting on top of it}
%     \item Because we are using the same dataset used to train virtuosoNet, we will directly compare the performance a Transformer model to the existing virtuosoNet models using the same quantitative metric, MSE. \rtodo[,inline]{Come up with specific model experiments and comparison in a table. Table doesn't have to have results but needs the general outline that will be used in the final paper}
    
% \end{itemize}

% \section{Evaluation}
% \begin{itemize}
%     \item Quantitative: Because we are using the same dataset used to train virtuosoNet, we will directly compare the performance a Transformer model to the existing virtuosoNet models using the same quantitative metric, MSE. \rtodo[,inline]{Come up with specific model experiments and comparison in a table. The table doesn't have to have results but needs the general outline that will be used in the final paper}
%     \item Due to time and resource constraints, no sophisticated qualitative evaluation was conducted for the models. However, a personal evaluation was used during the entire model development process. \rtodo[,inline]{Talk about method used for personal analysis}
%     \item 
% \end{itemize}
