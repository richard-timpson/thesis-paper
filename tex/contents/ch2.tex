\chapter{Background}\label{ch:ch2}
\rtodo[,inline]{Consider creating two backgrounds sections that are split into musical information and modeling information. The musical information can contain related work as well as background and context. The same can go for modeling}. 
% Provide additional context to the problem of expressive musical performance (EMP) and the model domain we are applying (Transformers). Make sure to talk about the intricacies behind the musical side of the problem, given that it is generally not as well known in computer science, ML, and AI. Introduce the idea of music information retrieval (MIR) research, and how EMP fit's into this research. Provide sufficient detail at a high level detailing exactly what EMP is and why it is an interesting problem, specifically for machine learning. Cover what type of data is required for the problem.

% Cover the Transformer and why it is worth it to apply this model to the problem domain. 

There are two major research components that this project is based on. The first is the problem domain of expressive musical performance (EMP), and the second is the ML modeling domain of Transformers. We will introduce both of these components and provide context for what makes them interesting as a research project and why they are worth exploring together. We start first with an overview and definition of EMP, and then a summary of the Transformer. 


\section{Expressive Musical Performance}\label{emp:sec}
EMP is a subset of the research field of Music Information Retrieval (MIR) whose purpose is to use computational information to study, interpret, and gain a better understanding of the \emph{essence} of music itself \cite{widmer2016getting}. Perhaps the most well known MIR application is that of a musical recommendation system used by streaming services such as Spotify \footnote{\url{spotify.com}} to provide a personalized and unique experience for each user. However, as \citet{widmer2016getting} suggests, there are a number of other non-trivial problems that face the field and will require significant effort from the research community to properly understand. A proper understanding of musical performance is one of them. 

MIR tasks can be broadly categorized in two ways - the first as computational methods for music analysis, and the second as computational methods for music generation. We are interested in the latter and its application in musical performance. In order to study how musical performance generation (and more particularly \emph{expressive} musical performance generation) models work, it is necessary to gain a proper understanding of the entire computational musical generation process as a whole. \citet{ji2020comprehensive} break the process down into 3 different components, with 4 different roles or agents that interact with that process. Figure \ref{fig:generation_process} shows each step in the process as well as the agents that participate \rtodo[,inline]{Try to get permission to reproduce the image in the paper}. 

\begin{figure}
    \centering
    \missingfigure{Image that shows different components of musical generation process}
    \caption{The first step of musical generation is composition, shown as a score in the figure. The second is performance, which is our area of interest. The third is the production of sound. Each different agent: composer, performer, instrument, and listener, can be thought of as a separate computational model in the generation process}
    \label{fig:generation_process}
\end{figure}

An EMP model is analogous to the performer as show in \ref{fig:generation_process}, who takes as input a musical composition and produces as output a performance. It is the phenomena of musical expression that makes the performance generation process interesting. Musical expression can be thought of as the performers' interpretation of a composition codified into different performance parameters that are intended to increase the quality of the musical experience by the final listener. Because the quality of a musical experience is highly subjective, there is no definition of what makes for a "correct" interpretation of a given composition \cite{cancino2018computational}. The subjective nature of EMP generation makes it a difficult problem to understand from a computational perspective. However, it also makes it a highly intriguing research topic given that a clear understanding of the problem from a computational perspective will no doubt further our understanding of what exactly it is that makes music so subjective in the first place, and bring us one step closer to understanding music itself. 

To properly understand exactly what it is that constitutes expression in musical performance, it is necessary to provide a detailed description of the first two components of the generation process - namely, scores and performances. We refer the reader to appendix \ref{ase:app_one_sect_1} which provides some basic terminology and concepts that will be useful for grasping the following section \footnote{Most of the appendix material may seem elementary to those who already have a background in music or musical notation. However, we feel that is necessary to include if for no other reason than to provide a clear definition for our descriptions both in general and at detailed mathematical level}. Due to the constraint of our data \rtodo{add reference} we focus only on western classical piano music. 

\subsection{Scores}\label{sec:scores}
A musical score is a symbolic representation of a musical composition. The symbolic notation used to create musical scores can be thought of as a language used to express musical ideas and information.  It presents this information in a hierarchical structure with different levels of musical detail at each level. The lowest level contains information about the pitch and timing of every single note, as well as optional information about how the note should be played. This can include information specific to instruments such as the bow direction of a violin, but for our purposes (dealing only with piano) we will consider this to be the articulation of each note, usually indicated by legato or staccato \rtodo[,inline]{Make sure to have some background information on articulation in the appendix}

The middle level contains information related to certain substructures within the musical composition, which are usually expressed within a grouping of notes or measures. The most common score annotations at this level are dynamic markings which indicate whether to play a grouping of notes loud (Forte), soft (Piano), or to gradually increase or decrease the volume (crescendo or decrescendo). %\rtodo{Add correct notation markings) %
Although dynamic markings are the most common at this level, it is also possible to see score markings for all other musical features, such as local tempo or articulation of a certain substructure. Perhaps the most important score marking at this level is that of a phrase, which is a marking that indicates that a group of notes should be interpreted as belonging to a singular musical idea and that each note should fit within the context of the phrase as a whole. A phrase can be expressed through all of the different aforementioned musical features, including the tempo, timing, dynamics, and articulation of the notes.

The highest level contains meta-information that relates to the entire composition as a whole. This information typically includes the key signature and time signature, as well as the global tempo for the entire piece, most commonly represented as BPM. 

\subsection{Peformance}\label{sec:performance}
An expressive musical performance contains most of the same musical information as does a score, but with one key difference; that is, that an expressive performance will deviate (or interpret) from the exact information that is presented in the score. For example, although a score may indicate a tempo of 120 BPM, it is highly unlikely that a given performer will perfectly adhere to this tempo throughout the entirety of the piece. This is even more apparent if the score indicates a change in tempo somewhere in the composition. If a score indicates that the performance should speed up over a series of notes, there is no telling at what rate the tempo should increase. Some performers may choose to speed up at a fast rate and over a short period of time. Others may choose to increase the tempo at a slow rate and over a longer period of time. A single accelerando (a score indication to pick up the tempo) can result in either of these outcomes. 

With that being said, a performance contains most of the same features related to a score, which include pitch, tempo, timing and articulation. Each of these expressive features will be measurable and absolute, whereas the score markings of these features can be viewed more as a suggestion than a rule. There a few additional features that are present in performances which are not in scores. The first we will refer to as deviation which is heavily related to timing. It is typically represented as a numerical number which represents how far off the timing of a particular note deviates from it's "correct" position in the score. These micro-timing deviations present in musical performances are an essential part of expression. Without them, indicating that each note onset and offset is exactly in line with its marking in the score, performances sound robotic and mundane \rtodo{add a reference, graphic, and sample performance}. 

The other important feature of performance that is not always present in a score applies specifically to the piano, and is the presence of a piano pedal. There are several different types of piano pedals, but the most common are the sustain pedal, which prolongs the duration of every note of the piano when activated, and the soft pedal which softens the sound of the entire piano. Although the effects of these pedals are directly related to the articulation and dynamics of the performance, their presence (or lack of) can be seen as a crucial component of piano performance. It is common for the sustain pedal to see active use in almost all modern piano performance, even when there doesn't exist any score marking indicating it's use. 

\rtodo[,inline]{Add section and reference to the specifics of feature engineering related to both the score and the performance in the methods section}. 

\subsection{Data}
The data required for EMP generation includes some digital form of representation of a score as well as a corresponding performance. Scores are typically given in the form of MusicXML, which is a text-based representation of a score. Performances could be directly be rendered as audio which is the process used by human performers with the use of an acoustic instrument. Instead of audio however, an intermediate data form, MIDI, is used to represent the performance. This better aligns with the generation process outlined in \ref{fig:generation_process}. In the full generation process, a separate model would be used to take the performance data in MIDI and synthesize that into raw audio which would be presented to the listener. Both data formats contain all of the required information to represent all of the musical components of both a score and a performance, including pitch, tempo, timing, articulation, deviation, and pedal. See appendix \ref{ase:app_one_sect_2} for more information on both MusicXML and MIDI. 

To build an EMP generation model, it is necessary to run both the score and performance through a data alignment process in which every note of the performance is mapped to it's corresponding position in the score. Given the highly dynamic nature of musical performance, it is a non-trivial task to run this alignment process for a set of scores and performances, especially if the task is performed by manual human annotation. There exist methods for both manual and automatic alignment. Due to the time-consuming nature of manual alignment and the need for large data sets to build higher quality models, automatic alignment algorithms are an active area of research. \rtodo[,inline]{Add reference to section which gives relevant research}

\begin{figure}
    \centering
    \missingfigure{Show why score to performance alignment matching is necessary.}
    \caption{Two performances of the same score can vary wildly in their tempo and timing. This makes it necessary to have a score to performance alignment for every performance. }
    \label{fig:alignemnt}
\end{figure}

\subsection{Features}
A common challenge facing any application of data-driven and ML-based research is to find the correct representation of data that a model interacts with. The choice of these data representations (or features in the ML terminology) have a large impact on the results of any EMP task, irregardless of the model. 

\subsubsection{Score Features}

There are some score features which are required for EMP models, which include the musical features at the lowest level of a score as explained in section \ref{sec:scores}. These are pitch and timing, and the duration of the notes. Mid-level features include concepts at the local level and have some music theoretic concepts, such as downbeat information of a given measure according to the time signature, or the tonality of a chord (tonic, dominant, etc). High-level features represent advanced music theoritic concepts that are more global to the entire piece, including abstract properties of the piece such as the emotion the piece should convey and how different sections of the piece relate to each to tell a complete story \cite{eduardo2018computational}. 

Both the mid-level and high-level features are not necessarily required for every EMP model as the lower-level features are, and are not consistent across all EMP models. It still remains an open question as to which features should be extracted from the data that the model can learn from. The lack of consistency in these features is one of the reasons that evaluation of EMP generation models is so difficult, as explained in section \ref{sec:evaluation}. \rtodo[,inline]{determine if this is the right place or not to outline the mathematical definition of the score features. Belongs either here or in the relevant work section}. 

\subsubsection{Performance Features}
For western classical solo piano music, performance features are relatively simple compared to the score features as well as to other instruments. Most EMP models use the different aspects of a piano performance as explained in section \ref{sec:performance} for their data features, including the pitch, tempo, timing (or timing deviation), articulation, and pedal. Although at an abstract level the features are the same, there are different numerical methods used to describe each of the different aspects. These are presented in \rtodo[,inline]{Add reference to relevant work section that goes over the different elements. This information may belong better here and then referenced in the relevant work section}. 

\subsection{Performance Evaluation}\label{sec:evaluation}
One of the most important components of any computational model performing a task is that of evaluation. Evaluation is used to determine the quality of a model, and serves as a benchmark to compare different models used in the same task. Due to the inherently subjective nature of music and musical performance discussed in \ref{emp:sec}, evaluation is notioursly difficult to understand and perform correctly for EMP generation models \cite{cancino2018computational}. 

Evaluation for computational models, specifically for EMP models, is typically categorized in two ways, quantitative evaluation and qualitatiative evaluation. Quantitative evaluation methods involve using numerical metrics which are computationally generated and deterministic. Qualitiative evaluation methods usually involve some form of human feedback and judgement presented in some standardized statistical measures. The key difference between quantitative and qualitiative is that qualitative methods are not as consisten and much more difficult to reproduce, given the reliance on the subjective feedback of human listeners. Traditionally, quantitative methods are preferred because of their consistency and reliability, In the case of EMP models however, qualitative evaluation methods may be even more important in gaining an understanding of what makes one model better than another. Finding good methods of evaluation is an active area of research in EMP \cite{cancino2018computational}. 

\subsubsection{Quantitative}
This method of evaluation is standard for ML models in general. There are a number of different metrics which are used in the evaluation process, all of which are specific to type of data and problem domain the model fits inside of. We will briefly cover the most common quantiative evaluation method that applies to our data and modeling domain, which is regression \rtodo{Add reference that discusses the feature engineering}. 

% Regression involves building a model that can output or predict real valued numbers, as opposed to classification models which output or predict a discrete number that identifies a "class" or a set of "classes". The trivial examples of both regression and classification are predicting the value of the stock market in the future (as a real number) and classifying whether an email is spam or not, respectively.

The two common metrics used for evaluation and regression are Mean-Squared-Error (MSE) and the Pearson Correlation Coefficient, usually denoted as the $R^2$ score. MSE is used to measure the difference between a prediction and an actual observed target value, and can be denoted as $MSE = \frac{1}{n}\sum_{i=1}^{n}(Y_i - \hat{Y_i})^2$, where $Y_i$ is the observed value at time step $i$, and $\hat{Y_1}$ is the predicted value. $R^2$ is a probablistic measure of the linear correlation between variables $X$ and $Y$, and is denoted as $\rho_{X,Y} = \frac{cov(X,Y)}{\sigma_{X}\sigma_{Y}}$ where cov indicates the covariance and $\sigma$ indicates the standard deviation. \footnote{See wikipedia for more information on \href{https://en.wikipedia.org/wiki/Mean_squared_error}{MSE}, \href{https://en.wikipedia.org/wiki/Covariance}{covariance}, \href{https://en.wikipedia.org/wiki/Standard_deviation}{standard deviation}, and \href{https://en.wikipedia.org/wiki/Pearson_correlation_coefficient}{the correlation coefficient}}

One of the problems with using quantiative, or "objective" evaluation methods, is that it usually invovles comparing a generated performance $\hat{Y}$ with a human performance ${Y}$. Given that no performance (or interpretation) of a can objectively been seen as better than another, this method of evaluation is also biasing the quality of a model towards some subjective view of the "correct" interpretation. Of course, a "correct" interpretation doesn't exist, which is what makes evalution methods for this particularly problem difficult. 

\subsubsection{Qualitative}
\rtodo[,inline]{Need to conduct more research before I can write this section. Haven't done so because I won't be performing a qualitative evaluation myself in the paper. However it is still worth mentioning}

\section{Transformers}\label{sec:transformers}
\rtodo[,inline]{Change the outline and sections to deal with general sequence modeling. Start by talking about LSTMS and then introduce Transformers in the context of machine translation}
To properly understand the significance of Transformers and their involvement in our work, it is necessary to provide context about the domain in which the Transformer was first introduced and give an overview of the existing work in that domain that the Transformer built on. We'll then provide some detail about the Transformer itself as well as adaptations of the original architectures and their results. 

\subsection{Natural Language Processing and Machine Translation}
One of the most commonly studied fields in Machine Learning and Artificial Intelligence is Natural Language Process (NLP), which (similarly to MIR) uses computation to ascertain a better understanding of human language as well as build technological tools that are useful in performing common language tasks. One such task is that of machine translation, which involves using computation alone to translate text from one language to another. NLP research usually invovles building sequence-based models (which explore the individual elements of an ordered set of items) due to the inherently sequential nature of language, as opposed to a non-sequential model which doesn't account for sequential data, such as a single image. Machine translation falls under the category of sequence-to-sequence (seq-2-seq) modeling problems, which involve the mapping and relationship of one sequence to another. This is typically in the form of translating a single sentence from one language (English) to another (French).

\newcommand{\mb}[1]{\mathbf{#1}}

More specifically, machine translation (and other seq-2-seq tasks) can be defined as taking an input sequence $\mb{x} = \{x_1, x_2, x_3,...x_m\}$ of size m and producing an output sequence $\mb{y} = \{y_1, y_2, y_3, ... y_n\}$ of size n such that $M(\mb{x}) = \mb{y}$, where $M$ can be any machine translation model. In some seq-2-seq tasks, $m = n$ are the same, implying that the input and output sequence are the same length. As is often the case in language translation, the input sentence and output sentence are of varying lengths, so we can assume that $m \neq n$. 

It is common to use an encoder-decoder architecture for $M$, where there is an encoder $E$ which takes in the input data and outputs and finds some hidden representation $E(\mb{x} = \mb{z})$. This hidden representation is given as input to the decoder, and the decoder uses it to produce the final output, $D(\mb{z}) = \mb{y}$. We can then define an encoder-decoder seq-2-seq model as $M(x) = D(E(\mb{x})) = \mb{y}$. Historically, a Long-Short-Term-Memory neural network (LSTM)\footnote{An LSTM is a common variant of a Recurrent Neural Network (RNN) which is the most standard deep learning model used for sequence modeling. See \url{https://en.wikipedia.org/wiki/Long_short-term_memory}} has been used for both $E$ and $D$, where the hidden representation $\mb{z}$ has been a fixed length vector \rtodo{Add reference}. 

One of the limitations of such a model is that it has to compress all of the information of the input data into the fixed-length vector $\mb{z}$ which causes the network to potentially lose important information, particularly in the case where an input sentence is given to the network which is longer than any present in the training data. \citet{bahdanau2014neural} present the attention mechanism which, used in conjunction with an RNN based encoder, allows for the hidden representation to itself be a sequence $\mb{z} = \{z_1, z_2, z_3, ..., z_m\}$ of size $m$ (the same size as the input sequence).    Each $z_i$ element in the sequence contains information about the whole input sequence, with an emphasis on the elements closest to the $i$-th element. This allows the hidden representation to encode any relationship that one element in the sequence has with another. The decoder then uses this information to "pay attention" to words in the output sequence that have a relationship with words in the input sequence, given the context that is encoded in the hidden representation at a particular time step $i$. The attention mechanism and model that uses it achieved state of the art results in the machine translation task, due in part to the fact that hidden representation is not limited to a fixed-size vector. The original attention mechanism presented by \citet{bahdanau2014neural} and its adaptations have since been used in tandum with recurrent models to improve the state of the art in several sequence modeling tasks \rtodo{find reference}. One of the limitations with standard recurrent networks is their inability to retain information across long sequences - attention provides a way to create additional context and better memory across these longer sequences which has led to the increase of performance in attention-based models. \rtodo{find reference}. 

\subsection{Attention is All You Need}

In the seminal paper, \citet{vaswani2017attention} introduce the Transformer. The Transformer is an encoder-decoder seq-2-seq modeling neural network architecture that relies solely on the use of attention and cuts out any semblance of a recurrent architecture. The Transformer was the first architecture to make use of attention by itself, and by doing so pushed the state of the art in machine translation even further than it had been with attention-based recurrent models. 

The Transformer architecture consists of a stack of $N$ layers, all of which use a combination of a self-attention (attention that applies only within a single input sequence and not between an input and a output sequence) \rtodo[,inline]{Explore different ways to describe self-attention. May not even be necessary at all to mention} mechanism along with a standard pointwise fully connected feed-forward neural network (FFNN). Both the encoder and decoder comprise of these attention based stacked layers. For a full description of the architecture see \cite{vaswani2017attention}. 

\subsection{Transformer Adaptations: BERT and GPT}
Of particular interest in the new Transformer modeling domain is powerful adaptations of the original architecture which have been applied to many other NLP tasks besides machine translation. On such architecture, BERT (which stands for Bidirectional Encoder Representations from Transformers), uses what can be referred to as an "encoder only" Transformer model. 

The original Transformer was built with machine translation in mind, but there are several other NLP tasks that could possibly benefti from using an attention only architecture. Some of these tasks include standard text classification, textual entailment, sentiment analysis, question answering, and many more \rtodo{Find reference}. BERT was introduced as an encoder only transformer model that could generalize to all of these tasks. The method which it made use of was pre-training the model on a massive data set, with the intuition that by feeding the model so much data that it would learn a general representation of language that could then be applied to several different tasks. BERT is effectively a massive encoder for language in general, and can be used in conjuction with other models as simple decoders to perform these tasks. See the original paper\cite{devlin2018bert} for the full architecture and details. 

Similarly to BERT, the Generative Pre-trained Transformer (GPT) architecture\cite{radford2019language} is an adaptation of the original Transformer. The GPT architecture can be seen as a "decoder only" transformer, and is used as a general Language Model (LM). The task of a LM is simple; to predict the next word in a sequence of given words. Given that GPT is a generative model, it employes the decoder side of the Transformer, which is responsible for actually generating the text as part of the machine translation taks. Similarly to BERT, GPT models are pre-trained on massive amounts of data to learn a general representation of language, and used in conjuction with other models to perform various tasks. 

Both BERT and GPT have significatly pushed the state of art in NLP and sequence modeling in general. Their success in the domain of language presents questions about their effectiveness in other related domains, such as music. 