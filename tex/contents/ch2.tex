\chapter{Background}\label{ch:ch2}
% Provide additional context to the problem of expressive musical performance (EMP) and the model domain we are applying (Transformers). Make sure to talk about the intricacies behind the musical side of the problem, given that it is generally not as well known in computer science, ML, and AI. Introduce the idea of music information retrieval (MIR) research, and how EMP fit's into this research. Provide sufficient detail at a high level detailing exactly what EMP is and why it is an interesting problem, specifically for machine learning. Cover what type of data is required for the problem.

% Cover the Transformer and why it is worth it to apply this model to the problem domain. 

There are two major research components that this project is based on. The first is the problem domain of expressive musical performance (EMP), and the second is the ML modeling domain of Transformers. We will introduce both of these components and provide context for what makes them interesting as a research project and why they are worth exploring together. We start first with an overview and definition of EMP, and then a summary of the Transformer. 

\section{Expressive Musical Performance}
EMP is a subset of the research field of Music Information Retrieval (MIR) \footnote{Widmer\cite{widmer2016getting} points out that MIR itself does not encompass the entire scope of computer music research, but that it is a good proxy to use when referring the field as a whole. We will operate under the same assumption} whose purpose is to use computational information to study, interpret, and gain a better understanding of the \emph{essence} of music itself \cite{widmer2016getting}. Perhaps the most well known MIR application is that of a musical recommendation system used by streaming services such as Spotify \footnote{\url{spotify.com}} to provide a personalized and unique experience for each user. However, as Widmer \cite{widmer2016getting} suggests, there are a number of other non-trivial problems that face the field and will require significant effort from the research community to properly understand. A proper understanding of musical performance is one of them. 

MIR tasks can be broadly categorized in two ways - the first as computational methods for music analysis, and the second as computational methods for music generation. We are interested in the latter and its application in musical performance. In order to study how musical performance generation (and more particularly \emph{expressive} musical performance generation) models work, it is necessary to gain a proper understanding of the entire computational musical generation process as a whole. \citet{ji2020comprehensive} break the process down into 3 different components, with 4 different roles or agents that interact with that process. Figure \ref{fig:generation_process} shows each step in the process as well as the agents that participate \rtodo[,inline]{Try to get permission to reproduce the image in the paper}. 

\begin{figure}
    \centering
    \missingfigure{Image that shows different components of musical generation process}
    \caption{The first step of musical generation is composition, shown as a score in the figure. The second is performance, which is our area of interest. The third is the production of sound. Each different agent: composer, performer, instrument, and listener, can be thought of as a separate computational model in the generation process}
    \label{fig:generation_process}
\end{figure}

An EMP model is analogous to the performer as show in \ref{fig:generation_process}, who takes as input a musical composition and produces as output a performance. It is the phenomena of musical expression that makes the performance generation process interesting. Musical expression can be thought of as the performers' interpretation of a composition codified into different performance parameters that are intended to increase the quality of the musical experience by the final listener. Because the quality of a musical experience is highly subjective, there is no definition of what makes for a "correct" interpretation of a given composition \cite{cancino2018computational}. The subjective nature of EMP generation makes it a difficult problem to understand from a computational perspective. However, it also makes it a highly intriguing research topic given that a clear understanding of the problem from a computational perspective will no doubt further our understanding of what exactly it is that makes music so subjective in the first place, and bring us one step closer to understanding music itself. 

To properly understand exactly what it is that constitutes expression in musical performance, it is necessary to provide a detailed description of the first two components of the generation process - namely, scores and performances. We refer the reader to appendix \ref{ase:app_one_sect_1} which provides some basic terminology and concepts that will be useful for grasping the following section \footnote{Most of the appendix material may seem elementary to those who already have a background in music or musical notation. However, we feel that is necessary to include if for no other reason than to provide a clear definition for our descriptions both in general and at detailed mathematical level}. Due to the constraint of our data \rtodo{add reference} we focus only on western classical piano music. 

\subsection{Scores}
A musical score is a symbolic representation of a musical composition. The symbolic notation used to create musical scores can be thought of as a language used to express musical ideas and information.  It presents this information in a hierarchical structure with different levels of musical detail at each level. The lowest level contains information about the pitch and timing of every single note, as well as optional information about how the note should be played. This can include information specific to instruments such as the bow direction of a violin, but for our purposes (dealing only with piano) we will consider this to be the articulation of each note, usually indicated by legato or staccato \rtodo[,inline]{Make sure to have some background information on articulation in the appendix}

The middle level contains information related to certain substructures within the musical composition, which are usually expressed within a grouping of notes or measures. The most common score annotations at this level are dynamic markings which indicate whether to play a grouping of notes loud (Forte), soft (Piano), or to gradually increase or decrease the volume (crescendo or decrescendo). %\rtodo{Add correct notation markings) %
Although dynamic markings are the most common at this level, it is also possible to see score markings for all other musical features, such as local tempo or articulation of a certain substructure. Perhaps the most important score marking at this level is that of a phrase, which is a marking that indicates that a group of notes should be interpreted as belonging to a singular musical idea and that each note should fit within the context of the phrase as a whole. A phrase can be expressed through all of the different aforementioned musical features, including the tempo, timing, dynamics, and articulation of the notes.

The highest level contains meta-information that relates to the entire composition as a whole. This information typically includes the key signature and time signature, as well as the global tempo for the entire piece, most commonly represented as BPM. 

\subsection{Peformance}
An expressive musical performance contains most of the same musical information as does a score, but with one key difference; that is, that an expressive performance will deviate (or interpret) from the exact information that is presented in the score. For example, although a score may indicate a tempo of 120 BPM, it is highly unlikely that a given performer will perfectly adhere to this tempo throughout the entirety of the piece. This is even more apparent if the score indicates a change in tempo somewhere in the composition. If a score indicates that the performance should speed up over a series of notes, there is no telling at what rate the tempo should increase. Some performers may choose to speed up at a fast rate and over a short period of time. Others may choose to increase the tempo at a slow rate and over a longer period of time. A single accelerando (a score indication to pick up the tempo) can result in either of these outcomes. 

With that being said, a performance contains most of the same features related to a score, which include pitch, tempo, timing and articulation. Each of these expressive features will be measurable and absolute, whereas the score markings of these features can be viewed more as a suggestion than a rule. There a few additional features that are present in performances which are not in scores. The first we will refer to as deviation which is heavily related to timing. It is typically represented as a numerical number which represents how far off the timing of a particular note deviates from it's "correct" position in the score. These micro-timing deviations present in musical performances are an essential part of expression. Without them, indicating that each note onset and offset is exactly in line with its marking in the score, performances sound robotic and mundane \rtodo{add a reference, graphic, and sample performance}. 

The other important feature of performance that is not always present in a score applies specifically to the piano, and is the presence of a piano pedal. There are several different types of piano pedals, but the most common are the sustain pedal, which prolongs the duration of every note of the piano when activated, and the soft pedal which softens the sound of the entire piano. Although the effects of these pedals are directly related to the articulation and dynamics of the performance, their presence (or lack of) can be seen as a crucial component of piano performance. It is common for the sustain pedal to see active use in almost all modern piano performance, even when there doesn't exist any score marking indicating it's use. 

\rtodo[,inline]{Add section and reference to the specifics of feature engineering related to both the score and the performance in the methods section}. 

\subsection{Data}
The data required for EMP generation includes some digital form of representation of a score as well as a corresponding performance. Scores are typically given in the form of MusicXML, which is a text-based representation of a score. Performances could be directly be rendered as audio which is the process used by human performers with the use of an acoustic instrument. Instead of audio however, an intermediate data form, MIDI, is used to represent the performance. This better aligns with the generation process outlined in \ref{fig:generation_process}. In the full generation process, a separate model would be used to take the performance data in MIDI and synthesize that into raw audio which would be presented to the listener. Both data formats contain all of the required information to represent all of the musical components of both a score and a performance, including pitch, tempo, timing, articulation, deviation, and pedal. See appendix \ref{ase:app_one_sect_2} for more information on both MusicXML and MIDI. 

To build an EMP generation model, it is necessary to run both the score and performance through a data alignment process in which every note of the performance is mapped to it's corresponding position in the score. Given the highly dynamic nature of musical performance, it is a non-trivial task to run this alignment process for a set of scores and performances, especially if the task is performed by manual human annotation. There exist methods for both manual and automatic alignment. Due to the time-consuming nature of manual alignment and the need for large data sets to build higher quality models, automatic alignment algorithms are an active area of research. \rtodo[,inline]{Add reference to section which gives relevant research}

\begin{figure}
    \centering
    \missingfigure{Show why score to performance alignment matching is necessary.}
    \caption{Two performances of the same score can vary wildly in their tempo and timing. This makes it necessary to have a score to performance alignment for every performance. }
    \label{fig:alignemnt}
\end{figure}

\section{Transformers}
In his seminal paper, \citet{vaswani2017attention} introduces the Transformer architecture - an attention only sequence neural network that achieved new state of the art results in neural machine translation tasks. The Transformer came as an alternative Deep Learning modeling method to the Recurrent Neural Network (RNN) and its common adaption as a Long Short Term Memory (LSTM) network in sequence modeling problems, specifically in the domain of Natural Language Processing (NLP). There have been several adaptations of the original architecture proposed by \citet{vaswani2017attention} which have also achieved state of the art results in many NLP tasks, such as the General Language Understanding Evaluation (GLUE) benchmark \cite{devlin2018bert}\cite{wang2018glue}, reading comprehension, question answering, and textual entailment \cite{brown2020language} \footnote{\href{https://ruder.io/nlp-imagenet/}{Some} have called the Transformer and its applications the "ImageNet moment for NLP", in reference to the famous AlexNet Convolutional Neural Network architecture introduced in 2012 \cite{krizhevsky2017imagenet} that has spearheaded the rise in Deep Learning research ever since}. 

\newcommand{\mb}[1]{\mathbf{#1}}

The original Transformer relies solely on the use of attention \cite{bahdanau2014neural},more specifically self-attention \rtodo{find a reference for self-attention}, mechanisms to build an encoder-decoder ANN that was used for a neural machine translation task, which involves translating text (usually in the form of a single sentence) from one language to another using a single ANN model. Machine translation can be seen as a standard seq-2-seq modeling problem, which involves mapping a input sequence $\mb{x} = \{x_1, x_2, x_3,...x_m\}$ of size m to an output sequence $\mb{y} = \{y_1, y_2, y_3, ... y_m\}$ of size n. An encoder-decoder type model is typically used for a seq-2-seq problem. In this model, the encoder $E$ will take the input sequence as input and generate a hidden encoding $E(\mb{x}) = \mb{z}$. The hidden encoding is fed as input to the decoder $D$ which outputs the target sequence $D(\mb{z}) = \mb{y}$. Historically, RNN based encoder-decoder models would use a fixed-sized vector for the hidden representation $\mb{z}$. However, this fixed-length vector was known to have limitations, specifically with sentences longer than those present in the training data \cite{bahdanau2014neural}. The introduction of attention allows for the hidden representation to itself be a sequence $\mb{z} = {z_1, z_2, z_3, ..., z_m}$ of length of $m$. The decoder decides which parts of the hidden representation to "pay attention" to, and uses this context to decide which word should be the next output of the sequence \cite{bahdanau2014neural}. This allows for information to propagate through the network without having to compress all of the information into a single fixed-sized vector. This mechanism achieved new state of the art results in machine translation \rtodo{Find reference} . 

The use of attention in sequence modeling (usually paired with an RNN) provided a way to create additional context and better memory across longer sequences, which had been a known limitation recurrent models \rtodo{Find reference}. It wasn't until the introduction of the Transformer that the attention mechanism was used completely outside of any other existing modeling architecture, and formed the basis of a model. 

The original Transformer \cite{vaswani2017attention} was also created for the neural machine translation task, but built both the encoder and decoder using a layered stack of self-attention (a form of attention which attends to only an input as opposed to using attention to find a relationship between an input and an output) mechanism along with a standard feed-forward neural network (FFNN). This attention only network architecture achieved new state of the art results in neural machine translation. 

% Since then their have been adaptations of the original architecture which have led to signi


% The encoder model will map the input sequence x into a hidden representation sequence $z = \{z_1, z_2, x_3, ... z_m\}$ which the decoder will then use to generate the output sequence $y$ \cite{vaswani2017attention}. Historically, LSTM based encoder-decoder models were used to achieve state of the art results \rtodo{Find references}. However, these models typically have a fixed size the introduction of attention and self-attention mechanisms in conjuction LSTM architectureswith \rtodo[,inline]{Add in definitions of LSTM, attention, self-attention, and how the Transformer uses self-attention to build an attention only NN}. 
% \section{Transformers}
% Provide context to why transformers are important and the problems they've solved in nlp. 
% \begin{itemize}
%     \item Intuition behind transformers and why they are so powerful in sequence modeling
%     \item Attention is all you need paper \cite{vaswani2017attention}
%     \begin{itemize}
%         \item State of the art in translation tasks
%         \item New architecture for sequence modeling using only attention. No recurrent network
%     \end{itemize}
%     \item BERT \cite{devlin2018bert}
%     \begin{itemize}
%         \item Transformer Encoder only 
%         \item Self-supervised learning and pre-training. Includes having a simple multi-layer perceptron at the end to make it useful
%     \end{itemize}
%     \item Music Transformer \cite{huang2018music}
%     \begin{itemize}
%         \item Builds off of This Time with Feeling\cite{oore2020time} paper. Both composition and performance generation at the same time 
%         \item Implements full transformer architecture 
%         \item Achieves better results than LSTM
%     \end{itemize}
%     \item Question: Can a transformer model be applied to only performance generation with an encoder only architecture to achieve better results than current state of the art models?. Intuition says yes given the results from Music Transformer. 
% \end{itemize}



\section{Evaluation}
\begin{itemize}
    \item Evaluation is particularly difficult for a problem like EPG because there is no "correct" interpretation of a score. However, there is at least a vaguely understood relationship between a score marking and how a performer should use that marking within the context of a performance. For example, if a crescendo marking is used in a score, the performer should at the very least increase the volume of the performance relative to the current volume of the piece. The amount which the volume should increase or the rate at which it increases are not clearly defined, but the fact of the increase of volume itself is. This is the fundamental intuition behind the motivation to build computational models for expressive performance. Nonetheless, it still remains a difficult job to evaluate a given EPG model because of the ambiguity of what is "correct" or not.
    \item Evaluation methods used so far in EPG models are broken into two categories, quantitative and qualitative. 
    \item Quantitative: 
    \begin{itemize}
        \item This follows standard techniques for experimentation of evaluation of ML models in general. It usually involves calculating a numerical value for a models inference on a separate test data set that was not used for model training or model selection. \rtodo{Find reference for ML training and evaluation}. Common metrics for regression like problems are mean squared error (MSE) and the pearson correlation coefficient (R2). 
        \item Due to the nature of EPG model evaluation mentioned above, it is not clear that "better" quantiative metric score for a given model over another indicates that the performance of the model is superior. \rtodo{Find section in Garcon survey that references this point}. 
    \end{itemize}
    \item Qualitative
    \begin{itemize}
        \item Qualitative evaluation methods involve gathering human feedback by playing performances of a given models performance to an audience and getting ratings or judgement of the model according to a predefined questionnare or survey method. The nature of these evaluation methods is not consistent in the current literature and remains a challenge for the field to solve in the future. \rtodo{Find section in Garcon survey that references this point}. 
        \item \rtodo[, inline]{Conduct more research for reference on current methods for qualititative evaluation}
    \end{itemize}
\end{itemize}


% Here shows to insert figures and cite figures in the main text.

% \begin{figure}[h!]
% \centering
% % \includegraphics[width = 0.85\linewidth]{./figs/ch2/lena.bmp}
% \caption{Picture of Lena}
% \label{fig:2-fig1}
% \end{figure}
% Picture of lena is shown in Fig. \ref{fig:2-fig1}.
