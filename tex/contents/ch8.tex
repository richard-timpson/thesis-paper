\chapter{Conclusion} \label{ch:ch8}
As we have outlined, this project underwent an unexpected evolution of purpose. Our initial goal was to determine if we could outperform the existing state-of-the-art EMP generation system with the same research methods and only a computational model change. The initial quantitative experiment results indicated that a Transformer does not outperform hierarchical-based recurrent models. However, when we ran our subjective evaluation comparing performance among the two families of models, we determined that declaring one model as better than another is not straightforward. This ambiguity led us to question the validity of the original research method, particularly with the evaluation metric, and shift our own toward more nuanced and discovery-based experiments. We want to use our experience in running these experiments to provide some high-level thoughts on some philosophical related to computational EMP. 

\section{Looking Forward: Finding the \emph{Essence} of Performance}
As we discussed and developed this project, one thought that plagued us is that we do not have a proper understanding of fundamental components that comprise musical performance. Without a strong background in music, it was hard to understand how to build and analyze our computational models. Widmer, in his \emph{Con Espressione}% 
\footnote{\emph{Con Espression} is the Italian phrase for ``with feeling'' and is used as a direction in musical notation.} Manifesto~\cite{widmer2016getting}, emphasizes the importance of focusing on discovering the \emph{essence} of music itself and using a more in-depth understanding to develop more impactful technology related to MIR. Given the success of Transformer models in NLP, we thought it would be relatively simple to empirically show that we can build better EMP models by throwing the powerful attention mechanism at a fundamentally sequence-based modeling problem, which had never been done. It is only after running our experiments and taking a step back to look at the results that we understand what Widmer means when he refers to the \emph{essence} of music. 

Our experience in developing this project convinces us that music's computational study is an inherently difficult problem, not because of the limits of computation but because of our current limited understanding of musical phenomena. It is relatively simple to experience music personally and share that experience with others. However, our (and Widmer's) conjecture is that there is a fundamental disconnect between our understanding of music's phenomenological aspect and the actual statistical patterns of nature that make music so appealing. MIR research attempts to encode these statistical patterns in computation, and as such, deriving results that are meaningful in practical application with real human interaction is non-trivial. Widmer suggests that we focus on understanding the relationship between music in nature and music as it is perceived, and we echo that sentiment here. 

A deeper understanding of music may be an essential component needed to derive better evaluation systems for performance, which is a driving factor in the future development of performance generation models. To create a proper evaluation system or metric, we first need to understand \emph{what exactly it is that constitutes a ``good'' or ``bad'' musical performance to a human listener}% 
\footnote{This is a separate question from determining the quality of a musical composition, or even of the synthesis of performance (whether it is the form of an acoustic instrument or a digital synthesizer). It is not clear where to draw the exact line between composition, performance, and synthesis from the human listener's perspective. Although we conceptualize them as independent from each other (which simplifies our mathematical assumptions), as shown in Figure \ref{fig:generation_process}, they may be entirely dependent or even the same phenomena expressed differently in nature. For example, a musician performing a Jazz improvisation on a guitar may use the physical process of synthesizing sound, such as how he strikes or bends a guitar string to reach a particular note, as driving factors in the musical piece. In this case, the guitar instrument's physical construction enables him to create musical subtleties in both the spontaneous composition and improvisation performance. Is there a clear cut line between what constitutes composition, performance, and synthesis in such a case?

On the other hand, we can analyze over 1000 symbolic musical compositions by Johann Sebastian Bach and their many musical adaptations over the last several hundred years. One example is the well-known adaptation of his Prelude No. 1 in C Major (BWV 846) as the accompaniment to a melody composed by Charles Gounod and set to the famous Latin prayer's lyrics, \emph{Ave Maria}. The original arrangement, published in 1853, was for violin (or cello) with the piano. It has since been arranged and performed countless times for different instruments, including guitar, string quartet, piano solo, solo vocal, and full choir. We can view the original piano Prelude as its own composition and separate from the many different adaptations in design, performance, and synthesis that complete the full musical experience. This ambiguity is one example of the considerations that need to be taken into account when creating the musical definitions necessary to build computational models.}. The answer to this question needs to come from a study in musicology, as well as computer science or artificial intelligence. 

We want to adopt Widmer's philosophy to guide our future explorations by drawing from the fields of musicology, music psychology, music cognition, and further advancement in computer science and mathematics to come closer to discovering this essence. From this work, we have learned that using the attention mechanism and Transformer models in EMP generation creates much more dynamic performances, both ``good'' and ``bad,'' than recurrence models. The \emph{essence} of this finding could be that using the long-term memory that attention provides allows more creative freedom in the performance process. The shorter-term memory of an LSTM may constrain the models to rely on global score features such as the overall tempo. It also may be the case that having too much creative freedom without respect for global conditioning breaks the inherent musical boundaries defined by cognitive perception. We found this to be the case with our Transformer models, which were so fast that they were ``unlistenable.'' 

Further experiments with modeling, data gathering, feature extraction, and evaluation, as well as an exploration of what determines a quality musical experience from a musicological and human cognitive perspective, will help answer these questions. We hope that we can continue to explore these problems using additional views drawing from musical research to come closer to finding the \emph{essence} of EMP performance and music as a whole. 
