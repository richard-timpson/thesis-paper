\chapter{Results} \label{ch:ch5}

\section{Quantitative Evaluation Results}
As discussed in section \ref{sec:experiments-and-evaluation}, the original purpose of this project was to determine if a Transformer based model could outperform the existing LSTM virtuosoNet models. Table \ref{tab:quantitative} shows the results of our experiments in comparison with the virtuosoNet models. The MSE metrics used for comparison with the virtuosoNet models are taken from \cite{jeong2019virtuosonet}. We also present the same performance metrics for our own LSTM baseline model as an additional comparison. All of the models presented in this table are trained using the standard MSE without weighted expressive parameters and use the articulation MSE calculation according to the pedal status as discussed in \ref{sec:qualitative-eval-problems}. To the best of our effort, all models were trained and evaluated using the same data, features, and evaluation metric. 

\rtodo[,inline]{Explain the results in the table when all experiments are done running}. 

% using macros in case the values change. 

% model configuration
\newcommand{\nep}{$N_{id}$}
\newcommand{\mn}{$M$} % mn for 'model name'
\newcommand{\nl}{$L$} % nl: num layers
\newcommand{\dhid}{$d_{hid}$} % dhid: dimension hidden size
\newcommand{\drop}{$D$} % D: Dropout
\newcommand{\lr}{$LR$} % LR: Learning Rate
\newcommand{\clip}{$C$} % C: gradient clip
\newcommand{\nh}{$H$} % nh: num heads

% Expressive features
\newcommand{\temp}{$t$}
\newcommand{\vel}{$v$}
\newcommand{\dev}{$d$}
\newcommand{\art}{$a$}
\newcommand{\ped}{$p$}


% my results
                  %total              %tempo              %vel              %dev              %articul              %pedal        
\readlist*\a{1.079915467915403, 0.8387099791654173, 1.3530433499396628, 1.017870266429722, 1.1067559519102133, 1.080384319222477} % 123 
\readlist*\b{0.8634560842141723, 0.5412064723018719, 0.8022146236503704, 0.8804639799541721, 0.8022366483458304, 0.9245564142364828} % 147 
\readlist*\c{0.8714990162701071, 0.5505609703737273, 0.7881732323421042, 0.9611995326543272, 0.8751485813981792, 0.9159152227103448} % 169 
\readlist*\d{0.8608967689267041, 0.5025553895868159, 0.7638317284792879, 0.878050578836977, 0.8178488211257614, 0.929653946913942} % 128 
\readlist*\e{0.8269241870319757, 0.4671040222800673, 0.7613456284477763, 0.8818908914978052, 0.8233950348666115, 0.8803471737534461} % 133 
\readlist*\f{0.892434075736163, 0.6518531192930515, 0.8248660148758638, 0.8837178772102976, 0.822714017388242, 0.9476605038763138} % 118 
\readlist*\g{0.931571010408277, 0.6190825817829081, 0.96866907527554, 0.8923720742977281, 1.0889969662761827, 0.9540228699651616} % 181 
\readlist*\h{0.8398954164095592, 0.5103522019637757, 0.7708808816209132, 0.9533001596417616, 0.8093733305095236, 0.8849918198915682} % 132 
\readlist*\i{0.9055077961121484, 0.7380731321188851, 0.8207453556958286, 0.9515869074832948, 0.8602034320048559, 0.9414252330302848} % 171 
\readlist*\j{1.005084838962903, 0.8624353822994071, 1.0529326007749042, 0.8987197173990472, 1.1763732810960201, 1.0093531322087683} % 173 
\readlist*\k{0.8352959967855129, 0.6160173766780894, 0.7846170962729531, 0.8910593114013335, 0.7908931125724473, 0.8722384046125028} % 188 
\readlist*\l{0.8463679141699834, 0.5445592460407571, 0.7492400507566016, 0.899280836268869, 0.8597047927381344, 0.8938945523819722} % 134 
\readlist*\m{0.8707426997177073, 0.4897337480780074, 0.7796597156133693, 0.8877784585332059, 0.8655195282458561, 0.9364968512758156} % 190 
\readlist*\n{0.8436574470387758, 0.4748660706616556, 0.8106850048921405, 0.8946506051604983, 0.8585572391965963, 0.8916389604554559} % 135 
\readlist*\o{0.9331073568122104, 0.6931559999619044, 0.9870281539322866, 0.9139575008493828, 1.1235607440091158, 0.9352111728264682} % 125 

% virtuosoNet results. Copied from other papers

                        % total      %temp, %vel, %dev, %art, %pedal  
\readlist*\vbl{0.7698181818181818, 0.4, 0.673, 0.773, 0.721, 0.843} 
\readlist*\vs{0.7324545454545454, 0.269, 0.607, 0.753, 0.688, 0.82} 
\readlist*\vm{0.7202727272727273, 0.22, 0.532, 0.747, 0.754, 0.81}

% lrv for learning rate value. Putting in command so that it doesn't ruin table alignment
\newcommand{\lrv}{\num{3e-5}}

\begin{table}
    \setlength{\tabcolsep}{0.4em}
    \setlength{\extrarowheight}{7pt}
    \sisetup{round-mode=places}
    \begin{center}
    \begin{tabular}{| c c | c c c c c c | S[round-precision=2] S[round-precision=2] S[round-precision=2] S[round-precision=2] S[round-precision=2] S[round-precision=2] |}
        \hline 
        \multicolumn{8}{|c|}{Model Configuration} & \multicolumn{6}{c|}{Results in MSE}\\
        \hline
        \nep & \mn & \nl & \dhid & \drop & \lr & \clip & \nh & Tot & \temp{} & \vel{} & {\dev{}} & \art{} & \ped{} \\ 
        % \nep & \mn & \nl & \dhid & \drop & \lr & \clip & \nh & 1 & 1 & 1 & 1 & 1 & 1 \\ 
        \hline 
123 & LSTM   & 3  & 256  & 0.1 & 0.1     & 0.5 &    & \a[1] & \a[2] & \a[3] & \a[4] & \a[5] & \a[6] \\ 
\hline
147 & T-BL   & 6  & 256  & 0.1 & 3e-5    & 0.5 & 6  & \b[1] & \b[2] & \b[3] & \b[4] & \b[5] & \b[6] \\
169 &        &    & 128  &     &         &     &    & \c[1] & \c[2] & \c[3] & \c[4] & \c[5] & \c[6] \\
128 &        &    & 528  &     &         &     &    & \d[1] & \d[2] & \d[3] & \d[4] & \d[5] & \d[6] \\
133 &        &    & 1024 &     &         &     &    & \e[1] & \e[2] & \e[3] & \e[4] & \e[5] & \e[6] \\
118 &        & 12 &      &     &         &     &    & \f[1] & \f[2] & \f[3] & \f[4] & \f[5] & \f[6] \\
181 &        & 24 &      &     &         &     &    & \g[1] & \g[2] & \g[3] & \g[4] & \g[5] & \g[6] \\
132 &        &    &      &     &         &     & 13 & \h[1] & \h[2] & \h[3] & \h[4] & \h[5] & \h[6] \\
171 &        &    &      & 0.2 &         &     &    & \i[1] & \i[2] & \i[3] & \i[4] & \i[5] & \i[6] \\
173 &        &    &      &     & 0.01    &     &    & \j[1] & \j[2] & \j[3] & \j[4] & \j[5] & \j[6] \\
188 &        &    &      &     &         &     & 26 & \k[1] & \k[2] & \k[3] & \k[4] & \k[5] & \k[6] \\
134 &        & 12 & 528  &     &         &     &    & \l[1] & \l[2] & \l[3] & \l[4] & \l[5] & \l[6] \\
190 &        & 12 &      &     &         &     & 13 & \m[1] & \m[2] & \m[3] & \m[4] & \m[5] & \m[6] \\
135 &        & 12 & 528  &     &         &     & 13 & \n[1] & \n[2] & \n[3] & \n[4] & \n[5] & \n[6] \\
125 &        & 24 & 528  &     &         &     &    & \o[1] & \o[2] & \o[3] & \o[4] & \o[5] & \o[6] \\
\hline
& HAN-BL &  - &  -   &  -  &    -    &  -  &  - & \vbl[1] & \vbl[2] & \vbl[3] & \vbl[4] & \vbl[5] & \vbl[6] \\
& HAN-S  &  - &  -   &  -  &    -    &  -  &  - & \vs[1]  & \vs[2]  & \vs[3]  & \vs[4]  & \vs[5]  & \vs[6] \\
& HAN-M  &  - &  -   &  -  &    -    &  -  &  - & \vm[1]  & \vm[2]  & \vm[3]  & \vm[4]  & \vm[5]  & \vm[6] \\
        \hline
    \end{tabular}
    \caption{A comparison of 3 different families of EMP generation models: virtuosoNet models, Transformer models, and our LSTM baseline models. The left side of the table presents the configuration for each of the models, exluding the virtuosoNet models which are present in other works \cite{jeong2019graph,jeong2019virtuosonet}. \nep{} is the ID of the Neptune experiment, \nl{} is the number of layers, \dhid{} is the dimension of the hidden layers, \drop{} is the dropout, \lr{} is the learning rate, \clip{} is the gradient clip, and \nh{} is the number of attention heads. The right side of the table presents the MSE results for all models along the five different expressive dimensions mentioned in \ref{sec:qualitative-eval-problems}, as well as the total MSE which is an aggregation of all the individual expressive features. The entries for the HAN models come from virtuosoNet and are given in \cite{jeong2019virtuosonet} }
    \label{tab:quantitative}
    \end{center}
\end{table}


\section{Qualitative Evaluation: Personal Analysis}\label{sec:qualitative-analysis}
In section \ref{sec:qualitative-eval-problems} we outline the evolution of our research method and identify major setbacks in the evaluation and comparison of our models. In our experience, our own qualitative evaluation through listening tests proved to be the most useful method for guiding our model development and analysis. With the full acknowledgment of the inherent bias that underlines such a method and the need for better quantitative evaluation metrics, we will present some of our observations as the model development progressed. 

The first general observation is that the two most important factors for overall performance are the tempo and pedal. Models that don't perform either of these two features within certain bounds correctly make performances almost unlistenable. If a performances global tempo is too fast and every other expressive parameter is learned correctly, the resulting performance will still sound bad enough that it's not worth listening to at all\footnote{Performances generated by models can be view through our \href{https://ui.neptune.ai/richt3211/thesis/experiments}{Neptune Project}. Each experiment has an ID and we've run performance generation code for many of the models. To listen to performances, visit an experiments artifacts tab and download available MIDI files which can be played in DAW software such as Logic Pro X. If performances don't exist for an experiment, contact the autor} \footnote{See \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-86/artifacts}{\tm{86} Fantaisie Impromptu} and \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-126/artifacts}{\tm{126} Etude Op. 10 No. 12}.}. We noticed a similar phenoema with the pedal. Some models generated performances with the sustain pedal applied at all times with hardly any break. The result is a performance that is completely muddied and unrefined. Although these performances are more bearable than those with extreme tempo, they are still hard to listen to in any meaningful way \footnote{See \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-125/artifacts}{\tm{125} Piano Sonata 11} }. 

% lm for lstm model
\newcommand{\lm}[1]{$LSTM_{N_{#1}}$}

We also notice that the tempo and timing of the Transformer models is more dynamic that the LSTM models, whether our own or from virtuosoNet. For some models the variability in timing seemed to be a good thing, while for others it was so bad that it almost sounded like the model was still "learning" how to play. The tempo for all LSTM based models (except for some slight variations in the performances from HAN-M \footnote{Performances for this model can be found at \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-162/artifacts}{$N_{126}$}}) was extremely consistent and non-changing to the point of sounding robotic and mundane. On one extreme with the Transformer the highly dynamic tempo at times sounds like a real performer making mistakes \footnote{See \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-86/artifacts}{$T_{N_{86}}$ Piano Sonata 11}}, while on the other with LSTM models the performance is so boring that it doesn't sound "human" at all \footnote{See \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-123/artifacts}{\lm{123} Piano Sonata 11}}. 

The pedaling in general of all models was mediocre at best. One of the observations of the qualitative analysis presented in \cite{jeong2019virtuosonet} is that the performances have too much pedal, which is consistent with our own. There are models whose performance pedaling is much better than others and follows the natural cadence of the music, but still don't quite match the use of pedal in actual human performance. Figure \ref{fig:pedal-difference} shows a visual comparison of the sustain pedal usage in different performances. 

\begin{figure}
    \centering
    \missingfigure{Images that show the difference of 3 performances, all of the same composition. One performance should have really bad pedal, another should have mediocre pedal, and the other (a human performance) should have natural pedal. Will be gathered with screenshots from Logic Pro}
    \caption{Test Caption}
    \label{fig:pedal-difference}
\end{figure}

The importance of tempo and pedal was part of the intuition that led to our formulation of the weighted MSE by expressive parameter defined in \ref{sec:qualitative-eval-problems}. We started out by running experiments with an even weight distribution and ended up with a model configuration that weights tempo and pedal significantly more than all others. We also ran these additional experiments changing the articulation mask. Because changing the loss function also changed our evaluation, we could not directly compare the quantitative results of the models, and so all evaluation was by our own qualitative listening test. We ran a few additional experiments with the tempo and pedal weighted high, along with some additional changes in the model size. A full description of the models and their parameters is given in table \ref{tab:qualitative-models}. 

% \newcommand{\nep}{$N_{id}$}
% \newcommand{\mn}{$M$} % mn for 'model name'
% \newcommand{\nl}{$L$} % nl: num layers
% \newcommand{\dhid}{$d_{hid}$} % dhid: dimension hidden size
% \newcommand{\drop}{$D$} % D: Dropout
% \newcommand{\lr}{$LR$} % LR: Learning Rate
% \newcommand{\clip}{$C$} % C: gradient clip
% \newcommand{\nh}{$H$} % nh: num heads
\newcommand{\am}{$AM$}

\begin{table}
    \setlength{\extrarowheight}{3pt}
    \begin{center}
    \begin{tabular}[]{| c | c c c c | c c c c c |}
        \hline
        \multicolumn{5}{|c|}{Model Configuration} & \multicolumn{5}{c|}{Expressive Weights}\\
        \hline
        \nep & \nl & \dhid & \nh & \am & $\al{t}$ & $\al{v}$ & $\al{d}$ & $\al{a}$ & $\al{p}$ \\ 
        \hline 
        150 & 256 & 6  & 6  & a & 1    & 1     & 1     & 1     & 7 \\
            &     &    &    & p & 1    & 1     & 1     & 1     & 7 \\
        154 &     &    &    &   & 0.2  & 0.2   & 0.2   & 0.2   & 0.2 \\
        156 &     &    &    &   & 0.33 & 0.11  & 0.11  & 0.11  & 0.33 \\
        157 &     &    &    &   & 0.4  & 0.067 & 0.067 & 0.067 & 0.4 \\
            &     &    &    & p & 0.4  & 0.067 & 0.067 & 0.067 & 0.4 \\
        159 & 528 & 12 & 13 &   & 0.4  & 0.067 & 0.067 & 0.067 & 0.4 \\
        \hline
    \end{tabular}
    \caption{The model configurations of additional experiments we ran after our initial quantitative evaluation effort. We show similar hyperparemters as in table \ref{tab:quantitative}, with an additional parameter \am which reprsents the articulation mask. A value of 'a' indicates that the articulation value was masked according to the note alignment, and a value of 'p' indicates that the articulation value was masked according to the pedal status. There are additional paramter values that are not present but are used in table \ref{tab:quantitative}: \lr{} is 0.0003, \clip{} is 0.5, and \drop{} is 0.1} 
    \label{tab:qualitative-models}
    \end{center}
\end{table}

\tm{154}, which weights all expressive parameters, generates performances with the global tempo a little too fast and an extremely muddy pedal. \tm{150} which uses the original MSE loss and weights the pedal high produces better performances with reasonable pedaling, although the tempo is inconsistent enough that the performance loses it's cohesiveness as a whole. For these reasons we increased both the tempo and pedal weights to be much higher than the others in models \tm{156} and \tm{157}. We found that the tempo and pedal weights \tm{156} were a bit too low - specifically, the pedal is almost just as muddy as it is in \tm{150} and the tempo is still a bit too fast, albeit more consistent and cohesive. We found that \tm{157} produced the best overall performance in the Transformer based models\footnote{All of these differences are best demonstrated in the performances of Fantaisie Impromptu. Compare \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-154/artifacts}{\tm{154}}, \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-150/artifacts}{\tm{150}}, \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-156/artifacts}{\tm{156}}, and \href{https://ui.neptune.ai/richt3211/thesis/e/THESIS-157/artifacts}{\tm{157}} }. It is likely that were we to continue to experiment with a different configuration the weights that we could come up with even better results. 

Our last general observation is that the virtuosoNet model HAN-M produces the best overall performances. We feel that in general the tempo for HAN-M is a little too slow, but it still creates the most natural expression. This is most apparent in it's performance of Beethoven's Piano Sonata 17 (also known as the "The Tempest"), whose introduction leaves a large space for interpetation to achieve a desired listening result. If the score is rendered exactly as it is, the resulting performance becomes boring and uninteresting. We found that the only model that made this performance "interesting", was the HAN-M. Although we have previously emphasized the problem with using the existing quantitative metric to evaluate our models, both our quantitative and qualitative evaluation of the HAN-M model indicates that it is the "best" model. The proposed Transformer architecture does not improve upon existing models. We will provide some intuition about why this is and possible model improvements for future work in section \rtodo{Add ref to discussion}. 





